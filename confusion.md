# Revelation through confusion
Let's discuss that one technical side that I find the most interesting.
As per machines input and output, in the end result human movements should be converted into sounds.
The proposed idea is to make the conversion complicated, unpredictable and hidden. Machine must emit not just single unconnected sounds, but a compositions with patterns, rhythm and interrelation.
As a simple example - raising a hand hear a specific sound as a simplistic approach must be abandoned, in order to disallow audience manipulate the output. 

Experiment should focus on illusion that Mirror "loads" its audience into memory, observes it for some time to study and remember, to adapt and synchronise. 

Thus, an other AI module is going to perform these tasks. 
So Mirror consists of 2 AI modules - one as a pose detections, and other one as a continuously learning system, that processes stores posed data to alter output Midi signal based on previous experience.

Mirror's task is primarily to study its subjects in time, and output rhythmic patterns in return, meaningful harmonic musical phrases based on pre programmed and shuffled patterns, as an arpeggiator, but the arpeggio is based on the collected data, and so is the BMP, which may change or remain static based on the setting. Current goal is floating BPM.

My work I focused on this specific part. I'm collaborating with a musical performer who consults me on musical theory and harmony.


